{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from scipy.stats import pearsonr, spearmanr\r\n",
    "\r\n",
    "\r\n",
    "cos_sim = lambda a, b: np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\r\n",
    "\r\n",
    "\r\n",
    "def compare_embeddings(embedding_one, embedding_two):\r\n",
    "    emb_one_is_list = isinstance(embedding_one[0], (list, np.ndarray))\r\n",
    "    emb_two_is_list = isinstance(embedding_two[0], (list, np.ndarray))\r\n",
    "\r\n",
    "    # pairwise compare all embeddings\r\n",
    "    if emb_one_is_list and emb_two_is_list:\r\n",
    "        if len(embedding_one) != len(embedding_two):\r\n",
    "            raise RuntimeError(\r\n",
    "                \"embedding one and embedding two lists not of equal length\"\r\n",
    "            )\r\n",
    "        return np.array([\r\n",
    "            cos_sim(e1, e2)\r\n",
    "            for e1, e2 in zip(embedding_one, embedding_two)\r\n",
    "        ])\r\n",
    "\r\n",
    "    # embedding one compared against all of embedding two\r\n",
    "    elif emb_two_is_list:\r\n",
    "        return [cos_sim(embedding_one, e2) for e2 in embedding_two]\r\n",
    "    # compare embedding one against embedding two\r\n",
    "    elif not emb_one_is_list:\r\n",
    "        return cos_sim(embedding_one, embedding_two)\r\n",
    "\r\n",
    "    # embedding one is a list of embeddings but embedding two is one embedding\r\n",
    "    raise RuntimeError(\r\n",
    "        \"Either Embedding one and two are lists of embeddings, else only embedding two.\"\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "def rescale_numeric(cos_dist, cur_min=-1, cur_max=1, new_min=0, new_max=5):\r\n",
    "    # percent of measurement on current scale\r\n",
    "    cur_perc = (cos_dist - cur_min) / (cur_max - cur_min)\r\n",
    "\r\n",
    "    # for scaling the measurement to the new range\r\n",
    "    scaling_fct = (new_max - new_min) + new_min\r\n",
    "    return cur_perc * scaling_fct\r\n",
    "\r\n",
    "\r\n",
    "def get_embedding_distances(s1_embeddings, s2_embeddings, scale=True):\r\n",
    "    distances = compare_embeddings(s1_embeddings, s2_embeddings)\r\n",
    "\r\n",
    "    # return cosine similarity unscaled\r\n",
    "    if not scale:\r\n",
    "        return distances\r\n",
    "\r\n",
    "    return rescale_numeric(distances)\r\n",
    "\r\n",
    "\r\n",
    "# todo: proper benchmark\r\n",
    "def eval_embedding_correlation(distances, truth_vector):\r\n",
    "    pearson_corr, pearson_pval = pearsonr(distances, truth_vector)\r\n",
    "    spearman_corr, spearman_pval = spearmanr(distances, truth_vector)\r\n",
    "\r\n",
    "    return pd.DataFrame({\r\n",
    "        \"type\": [\"pearson\", \"spearman\"],\r\n",
    "        \"corr\": [pearson_corr, spearman_corr],\r\n",
    "        \"pval\": [pearson_pval, spearman_pval],\r\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(sts_df, encode_func):\r\n",
    "    s1_embeddings = encode_func(sts_df.sent1.values)\r\n",
    "    s2_embeddings = encode_func(sts_df.sent2.values)\r\n",
    "    gold_standard = sts_df.score.values\r\n",
    "\r\n",
    "    embedding_distances = get_embedding_distances(\r\n",
    "        s1_embeddings,\r\n",
    "        s2_embeddings)\r\n",
    "\r\n",
    "    return(eval_embedding_correlation(embedding_distances, gold_standard))\r\n",
    "\r\n",
    "# benchmark_model(train_sentences, model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import gzip\r\n",
    "import csv\r\n",
    "\r\n",
    "from sentence_transformers import util\r\n",
    "from sentence_transformers.readers import *\r\n",
    "\r\n",
    "\r\n",
    "def cache_sts_eval_data(\r\n",
    "    dataset = \"stsbenchmark\",\r\n",
    "    save_dir = \"../data/inference\",\r\n",
    "    force = False):\r\n",
    "    file_path = f\"{save_dir}/{dataset}.tsv.gz\"\r\n",
    "\r\n",
    "    if not os.path.exists(file_path) or force:\r\n",
    "        print(\"fetching dataset...\")\r\n",
    "        fetch_path = f\"https://sbert.net/datasets/{dataset}.tsv.gz\"\r\n",
    "        util.http_get(fetch_path, file_path)\r\n",
    "    else:\r\n",
    "        print(\"dataset already exsits...\")\r\n",
    "    \r\n",
    "    return file_path\r\n",
    "\r\n",
    "\r\n",
    "def load_sent_trans_data(dataset_gz=None):\r\n",
    "    if dataset_gz is None:\r\n",
    "        dataset_gz = cache_sts_eval_data()\r\n",
    "\r\n",
    "    test_sts_samples = []\r\n",
    "    dev_sts_samples = []\r\n",
    "    train_sts_samples = []\r\n",
    "    with gzip.open(dataset_gz, \"rt\", encoding=\"utf8\") as file_in:\r\n",
    "        reader = csv.DictReader(\r\n",
    "            file_in,\r\n",
    "            delimiter=\"\\t\",\r\n",
    "            quoting=csv.QUOTE_NONE)\r\n",
    "\r\n",
    "        for row in reader:\r\n",
    "            score = row.get(\"label\",)\r\n",
    "\r\n",
    "            if \"score\" in row:\r\n",
    "                # rescale to 0 - 1\r\n",
    "                score = float(row.get(\"score\", None)) / 5.0\r\n",
    "\r\n",
    "            assert score is not None, \"could not detect label\"\r\n",
    "\r\n",
    "            inp_example = InputExample(\r\n",
    "                texts=[\r\n",
    "                    row[\"sentence1\"],\r\n",
    "                    row[\"sentence2\"]\r\n",
    "                ],\r\n",
    "                label=score)\r\n",
    "\r\n",
    "\r\n",
    "            if row[\"split\"] == \"test\":\r\n",
    "                test_sts_samples.append(inp_example)\r\n",
    "            elif row[\"split\"] == \"dev\":\r\n",
    "                dev_sts_samples.append(inp_example)\r\n",
    "            else:\r\n",
    "                train_sts_samples.append(inp_example)\r\n",
    "\r\n",
    "    return train_sts_samples, dev_sts_samples, test_sts_samples\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exsits...\n"
     ]
    }
   ],
   "source": [
    "# fetch data\r\n",
    "sts_train, sts_dev, sts_test = load_sent_trans_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exsits...\n",
      "evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>steps</th>\n",
       "      <th>cosine_pearson</th>\n",
       "      <th>cosine_spearman</th>\n",
       "      <th>euclidean_pearson</th>\n",
       "      <th>euclidean_spearman</th>\n",
       "      <th>manhattan_pearson</th>\n",
       "      <th>manhattan_spearman</th>\n",
       "      <th>dot_pearson</th>\n",
       "      <th>dot_spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.836131</td>\n",
       "      <td>0.841234</td>\n",
       "      <td>0.808878</td>\n",
       "      <td>0.806445</td>\n",
       "      <td>0.806642</td>\n",
       "      <td>0.803589</td>\n",
       "      <td>0.639891</td>\n",
       "      <td>0.634872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  steps  cosine_pearson  cosine_spearman  euclidean_pearson  \\\n",
       "0     -1     -1        0.836131         0.841234           0.808878   \n",
       "\n",
       "   euclidean_spearman  manhattan_pearson  manhattan_spearman  dot_pearson  \\\n",
       "0            0.806445           0.806642            0.803589     0.639891   \n",
       "\n",
       "   dot_spearman  \n",
       "0      0.634872  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "from sentence_transformers import SentenceTransformer\r\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\r\n",
    "\r\n",
    "\r\n",
    "def run_evaluator(model,\r\n",
    "                  model_name,\r\n",
    "                  dataset=None,\r\n",
    "                  evaluator_name=\"sts-test\",\r\n",
    "                  outdir=\"../data/inference/sts\"):\r\n",
    "    if dataset is None:\r\n",
    "        _, _, dataset = load_sent_trans_data()\r\n",
    "\r\n",
    "    sts_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\r\n",
    "        sts_test,\r\n",
    "        name=evaluator_name\r\n",
    "    )\r\n",
    "\r\n",
    "    outdir = f\"{outdir}/{model_name}\"\r\n",
    "    os.makedirs(outdir, exist_ok=True)\r\n",
    "\r\n",
    "    results_path = \\\r\n",
    "        f\"{outdir}/similarity_evaluation_{evaluator_name}_results.csv\"\r\n",
    "\r\n",
    "    if os.path.exists(results_path):\r\n",
    "        os.remove(results_path)\r\n",
    "\r\n",
    "    print(\"evaluating model...\")\r\n",
    "    sts_evaluator(model, output_path=outdir)\r\n",
    "\r\n",
    "    return pd.read_csv(results_path)\r\n",
    "\r\n",
    "\r\n",
    "model_name = \"paraphrase-MiniLM-L6-v2\"\r\n",
    "sts_model = SentenceTransformer(model_name)\r\n",
    "run_evaluator(sts_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 690/690 [00:00<00:00, 719kB/s]\n",
      "Downloading: 100%|██████████| 2.15k/2.15k [00:00<00:00, 1.10MB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 61.1kB/s]\n",
      "Downloading: 100%|██████████| 248/248 [00:00<00:00, 61.3kB/s]\n",
      "Downloading: 100%|██████████| 480M/480M [02:06<00:00, 3.79MB/s]\n",
      "Downloading: 100%|██████████| 4.61M/4.61M [00:02<00:00, 1.83MB/s]\n",
      "Downloading: 100%|██████████| 164/164 [00:00<00:00, 20.5kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 32.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exsits...\n",
      "evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>steps</th>\n",
       "      <th>cosine_pearson</th>\n",
       "      <th>cosine_spearman</th>\n",
       "      <th>euclidean_pearson</th>\n",
       "      <th>euclidean_spearman</th>\n",
       "      <th>manhattan_pearson</th>\n",
       "      <th>manhattan_spearman</th>\n",
       "      <th>dot_pearson</th>\n",
       "      <th>dot_spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.621784</td>\n",
       "      <td>0.615356</td>\n",
       "      <td>0.598526</td>\n",
       "      <td>0.614718</td>\n",
       "      <td>0.605307</td>\n",
       "      <td>0.617694</td>\n",
       "      <td>0.32855</td>\n",
       "      <td>0.321752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  steps  cosine_pearson  cosine_spearman  euclidean_pearson  \\\n",
       "0     -1     -1        0.621784         0.615356           0.598526   \n",
       "\n",
       "   euclidean_spearman  manhattan_pearson  manhattan_spearman  dot_pearson  \\\n",
       "0            0.614718           0.605307            0.617694      0.32855   \n",
       "\n",
       "   dot_spearman  \n",
       "0      0.321752  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model_name = \"average_word_embeddings_glove.6B.300d\"\r\n",
    "glove_model = SentenceTransformer(glove_model_name)\r\n",
    "\r\n",
    "run_evaluator(glove_model, glove_model_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58cc34421d6f8e6ec3ff7f39e3e3bf81e1fa1daec9f1ba909980818e3b24d324"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('s_transformers': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}